{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "ID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12: Generative Adversarial Networks\n",
    "\n",
    "We have seen that in the unsupervised learning setting, we are given a training dataset\n",
    "$(\\textbf{x}^{(1)}, \\ldots, \\textbf{x}^{(m)})$, $\\textbf{x}^{(i)} \\in \\mathcal{X}$.\n",
    "and our goal is to output a model that expresses the structure of the dataset.\n",
    "\n",
    "Many unsupervised learning algorithms such as the EM algorithm for Gaussian mixture models\n",
    "estimate a probability density model $h_\\theta(\\textbf{x}) = p(\\textbf{X}=\\textbf{x} ; \\theta)$.\n",
    "The GMM is an explicit parametric probability density estimator.\n",
    "\n",
    "A completely different approach to probability density modeling is represented by the recently\n",
    "introduced Generative Adversarial Network (GAN) density model.\n",
    "GANs were [introduced in 2014 by Ian Goodfellow and colleagues](https://arxiv.org/abs/1406.2661).\n",
    "\n",
    "The idea is simple. We assume that the training data were sampled i.i.d. from a\n",
    "distribution $p_{\\text{data}}(\\mathbf{x})$ over $\\mathcal{X}$. We define a prior\n",
    "density $p_\\textbf{z}(\\textbf{z})$ over a set of possible \"noise vectors\" $\\mathcal{Z}$,\n",
    "(usually, $\\mathcal{Z} = \\mathbb{R}^d$), then we try to come up with a neural network *generator*\n",
    "$G(\\mathbf{z};\\theta_g)$ whose goal is to transform noise inputs $\\mathbf{z} \\sim p_\\mathbf{z}(\\mathbf{z})$\n",
    "into outputs $\\mathbf{x} = G(\\mathbf{z};\\theta_g)$\n",
    "distributed (as closely as possible) according to $p_\\text{data}(\\mathbf{x})$.\n",
    "We also create and train a neural network *discriminator*\n",
    "$D(\\mathbf{x};\\theta_d)$ whose goal is to distinguish \"real\" samples from the training set from\n",
    "\"fake\" samples from $G$.\n",
    "\n",
    "Formally, $G$ and $D$ play a minimax game with value function $V(D,G)$:\n",
    "$$\\min_G \\max_D V(D,G) = \\mathbb{E}_{\\mathbf{x} \\sim p_\\text{data}(\\mathbf{x})}\\left[\\log D(\\textbf{x})\\right] +\n",
    "                         \\mathbb{E}_{\\mathbf{z} \\sim p_\\mathbf{z}(\\mathbf{z})}\\left[\n",
    "                           \\log(1-D(G(\\textbf{z}))\\right]. $$\n",
    "                   \n",
    "Again, the generator's goal is to \"trick\" the discriminator into thinking its outputs are samples from\n",
    "$p_\\text{data}(\\mathbf{x})$.\n",
    "The generator *implicitly* defines a probability density $p_g(\\mathbf{x})$ over $\\mathcal{X}$.\n",
    "The generator wins the minimax game when $p_g = p_\\text{data}$.\n",
    "\n",
    "One type of application of the GAN is to generate images according to a\n",
    "target distribution. [Goodfellow's original GAN paper](https://arxiv.org/abs/1406.2661)\n",
    "demonstrates the ability of their GANs to generate images similar to those in the MNIST\n",
    "handwritten digit dataset and the CIFAR-10 common object image dataset.\n",
    "Here is the basic GAN model described by Goodfellow et al. (2014):\n",
    "\n",
    "<img src=\"img/gan_architecture-1.png\" title=\"GAN Framework\" style=\"width: 640px;\" />\n",
    "\n",
    "Since 2014, GANs and their cousins have led to some of the most startling advances artificial intelligence\n",
    "has seen during this time. See, for example, our favorite GAN variant, the\n",
    "[CycleGAN](https://arxiv.org/abs/1703.10593),\n",
    "which combines two generators and two discriminators and can do incredibly amazing things like\n",
    "[turn horses into zebras](https://junyanz.github.io/CycleGAN/) or\n",
    "[super-resolve images of peoples' faces](https://link.springer.com/article/10.1007%2Fs00521-021-05973-0).\n",
    "\n",
    "In this lab, we'll develop several basic GANs and experiment with them. Some of the material here is derived\n",
    "from Coursera's *Build Basic Generative Adversarial Networks*.\n",
    "\n",
    "After this lab, you may be interested in [6 GAN Architectures You Really Should Know](https://neptune.ai/blog/6-gan-architectures).\n",
    "\n",
    "## Generator\n",
    "\n",
    "The generator in a GAN is driven by a noise vector\n",
    "sampled from the \"latent space\" $\\mathcal{Z}$ according to $p_\\mathbf{z}$ and transforms that\n",
    "noise sample into an element of $\\mathcal{X}$, the domain of $p_{data}$.\n",
    "\n",
    "<img src=\"img/Generator.jpg\" title=\"Generator\" style=\"width: 640px;\" />\n",
    "\n",
    "The generator in a GAN is used to generate examples and is the model we're invested in and helping\n",
    "to achieve high performance at the end of the training process.\n",
    "\n",
    "The generator's final goal is to produce examples from a certain class. So if you trained it from the class of a cat, then the generator will do some computations and output a representation of a cat that looks as real as\n",
    "possible.\n",
    "\n",
    "<img src=\"img/generateCat.PNG\" title=\"Generator-Cat\" style=\"width: 640px;\" />\n",
    "\n",
    "Clearly, yhe generator should not output the same cat every time it runs.\n",
    "To ensure that it is able to produce different examples each time it is invoked,\n",
    "we actually input different samples from the noise distribution.\n",
    "\n",
    "Noise vector is actually just a set of values where these differently shaded cells are just different values. So you can think of this as 1, 2, 5, 1.5, 5, 5, 2. Then this noise vector is fed in as input, sometimes with\n",
    "additional information such as a class $y$ for the class \"cat\" into the generator's neural network.\n",
    "This means that these features, $x_0$, $x_1$, $x_2$, all the way up to $x_n$, include the class, as well as, the numbers in this noise vector. Then the generator in this neural network will compute a series of nonlinearities from those inputs and return some variables that look link an image.\n",
    "\n",
    "In another run, it may generate a cat or a dog or even a horse. These are all with a different noise vectors and each noise vector can be red nose, short hair and other. These things can be learned from Discriminator model.\n",
    "\n",
    "## Discriminator\n",
    "\n",
    "The discriminator has the responsibity to classify its input as\n",
    "real or fake. When a fake sample from the generator is given, it should ouptut 0 for fake:\n",
    "\n",
    "<img src=\"img/DiscriminatorFake.png\" title=\"Discriminator-1\" style=\"width: 640px;\" />\n",
    "\n",
    "On the other hand, if the input is real, it shoudl output 1 for real:\n",
    "\n",
    "<img src=\"img/DiscriminatorReal.jpg\" title=\"Discriminator-2\" style=\"width: 640px;\" />\n",
    "\n",
    "Discriminator models is the probability of an example being fake given a set of input $X$. It will look at the image of fake cats and determined that they are about 80% probability it isn't the real one, so it will classify as **FAKE**.\n",
    "\n",
    "<img src=\"img/FakeCat.jpeg\" title=\"Fake cat\" style=\"width: 512px;\" />\n",
    "\n",
    "On the other hand, it will look at another cat image and determined that they are about 5% probability it isn't the real one, so it will classify as **REAL**.\n",
    "\n",
    "<img src=\"img/RealCat.jpeg\" title=\"Real cat\" style=\"width: 256px;\" />\n",
    "\n",
    "It uses the probability to feedback to the generator models, then generator model will learn from the punishment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The optimizer\n",
    "\n",
    "As explained above, the optimization is a minimax game.\n",
    "The generator wants to minimize the objective function, whereas the discriminator wants to maximize the same objective function.\n",
    "\n",
    "<img src=\"img/GanObjectivefunction.png\" title=\"min-max optimization\" style=\"width: 640px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Generate a mixture of Gaussians\n",
    "\n",
    "Suppose we have an unknwon distribution $p_\\text{data}(\\mathbf{x})$ that is in fact a mixture of three Gaussian distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Sample from p_data(x):\n",
    "def sample_pdata(m):\n",
    "    means_gt = [ [1,10], [10,1], [10,10] ]\n",
    "    sigmas_gt = [ np.matrix([[1, 0],[0, 1]]), np.matrix([[4,0],[0,1]]),\n",
    "                  np.matrix([[1,0],[0,4]]) ]\n",
    "    phi_gt = [ 0.2, 0.2, 0.6 ]\n",
    "    n = len(means_gt[0])\n",
    "    k = len(phi_gt)\n",
    "    Z = [0]*m\n",
    "    X = np.zeros((m,n))\n",
    "    # Generate m samples from multinomial distribution using phi_gt\n",
    "    z_vectors = np.random.multinomial(1, phi_gt, size=m)  # Result: binary matrix of size (m x k)\n",
    "    for i in range(m):\n",
    "        # Convert one-hot representation z_vectors[i,:] to an index\n",
    "        Z[i] = np.where(z_vectors[i,:] == 1)[0][0]\n",
    "        # Grab ground truth mean mu_{z^i}\n",
    "        mu = means_gt[Z[i]]                \n",
    "        # Grab ground truth covariance Sigma_{z^i}\n",
    "        sigma = sigmas_gt[Z[i]]\n",
    "        # Sample a 2D point from mu, sigma\n",
    "        X[i,:] = np.random.multivariate_normal(mu,sigma,1)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a sample from this ground truth distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_pdata(100)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "plt.title('Sample from p_data(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need a function to sample from the noise distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_noise(m, n):\n",
    "    return np.random.multivariate_normal([0,0],[[1, 0],[0, 1]], m)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a sample from the noise distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sample_noise(100, 2)\n",
    "\n",
    "plt.scatter(Z[:,0],Z[:,1])\n",
    "plt.title('Sample from p_z(z)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a discriminator and generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GeneratorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(2, 20)\n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.output = nn.Linear(20, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass data through fc1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        output = self.output(x)\n",
    "        return output\n",
    "    \n",
    "class DiscriminatorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        # First fully connected layer\n",
    "        self.fc1 = nn.Linear(2, 20)\n",
    "        # Second fully connected layer\n",
    "        self.fc2 = nn.Linear(20, 20)\n",
    "        self.fc3 = nn.Linear(20,20)\n",
    "        self.output = nn.Linear(20, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1()\n",
    "        x = self.output2(x)\n",
    "        return F.sigmoid(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create instances of the generator and discriminator and test that G() can process a sample from the noise distribution and that D() can process a sample from the data distribution or the output of the generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the generator and discriminator\n",
    "\n",
    "G = GeneratorNet()\n",
    "D = DiscriminatorNet()\n",
    "\n",
    "# xhat = G(noise sample)\n",
    "\n",
    "z = torch.tensor(sample_noise(10, 2)).float()\n",
    "print('Generator input:', z)\n",
    "xhat = G(z)\n",
    "print('Generator output:', xhat)\n",
    "\n",
    "# decisions on fake data = D(G(noise sample))\n",
    "\n",
    "decisions_fake = D(xhat)\n",
    "print('Discriminator output for generated data:', decisions_fake)\n",
    "\n",
    "# decisions on real data = D(data sample)\n",
    "\n",
    "x = torch.tensor(sample_pdata(10)).float()\n",
    "decisions_real = D(x)\n",
    "print('Discriminator output for real data:', decisions_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some code to train these models using the algorithm from Goodfellow et al. (2014):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from torch import optim\n",
    "%matplotlib inline\n",
    "\n",
    "num_iters = 1000\n",
    "num_minibatches_discriminator = 5\n",
    "minibatch_size = 100\n",
    "n = 2\n",
    "\n",
    "G = GeneratorNet()\n",
    "D = DiscriminatorNet()\n",
    "\n",
    "D_optimizer = optim.Adam(D.parameters(), lr=0.001)\n",
    "G_optimizer = optim.Adam(G.parameters(), lr=0.001)\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# for number of training iterations\n",
    "\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "def do_plot(d_losses, g_losses):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(d_losses, label='Discriminator')\n",
    "    plt.plot(g_losses, label='Generator')\n",
    "    plt.title('GAN loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "G.train()\n",
    "D.train()\n",
    "\n",
    "for iter in range(num_iters):\n",
    "    \n",
    "    # Train discriminator for num_minibatches_discriminator minibatches\n",
    "\n",
    "    d_loss = 0\n",
    "    for discriminator_iter in range(num_minibatches_discriminator):\n",
    "        D.zero_grad()\n",
    "        D_optimizer.zero_grad()\n",
    "        x = torch.tensor(sample_pdata(minibatch_size)).float()\n",
    "        z = torch.tensor(sample_noise(minibatch_size, n)).float()\n",
    "        xhat = G(z)\n",
    "        decisions_real = D(x)\n",
    "        real_targets = torch.ones(minibatch_size, 1)\n",
    "        error_real = loss(decisions_real, real_targets)\n",
    "        error_real.backward()\n",
    "        decisions_fake = D(xhat)\n",
    "        fake_targets = torch.zeros(minibatch_size, 1)\n",
    "        error_fake = loss(decisions_fake, fake_targets)\n",
    "        error_fake.backward()\n",
    "        D_optimizer.step()\n",
    "        d_loss += error_real + error_fake\n",
    "\n",
    "    # Train generator on one minibatch\n",
    "    \n",
    "    G.zero_grad()\n",
    "    D.zero_grad()\n",
    "    G_optimizer.zero_grad()\n",
    "    z = torch.tensor(sample_noise(minibatch_size, n)).float()\n",
    "    xhat = G(z)\n",
    "    decisions_fake = D(xhat)\n",
    "    fake_targets = torch.ones(minibatch_size, 1)\n",
    "    g_loss = loss(decisions_fake, fake_targets)\n",
    "    g_loss.backward()\n",
    "    G_optimizer.step()\n",
    "\n",
    "    d_losses.append(d_loss.item())\n",
    "    g_losses.append(g_loss.item())\n",
    "    \n",
    "    do_plot(d_losses, g_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "z = torch.tensor(sample_noise(100, 2)).float()\n",
    "xhat = G(z).detach().numpy()\n",
    "\n",
    "plt.scatter(xhat[:,0],xhat[:,1])\n",
    "plt.title('Data generated by GAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de3ee2d6fded3d10bb59826917ee9bf5",
     "grade": false,
     "grade_id": "cell-293c64948da99148",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Exercise 1 (50 points)\n",
    "\n",
    "As the results are not yet convincing, perform some further experiments with bigger noise vectors, larger networks, and different hyperparameters to improve the results. In your report, describe your experiments and demonstrate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70f5387d5a7bf1c0d0f44f698f8623b0",
     "grade": false,
     "grade_id": "cell-762b7a27cfe729bf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Deep Convolutional GAN\n",
    "\n",
    "This DCGAN tutorial is from the [DCGAN Tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) and the data is from [Mckinsey666](https://github.com/Mckinsey666/Anime-Face-Dataset)\n",
    "\n",
    "The goal of this paper is to generate fake images like as shown below. For this lab we will use 2000 of the original 60,000 images.\n",
    "![DCGAN Results](https://lh3.googleusercontent.com/2O3GwarTHA1detFNPHfBYAWZTj6ZATp0K1vdHtjdNHlCvQp_bSnXcMRI3oD-EEeCpI4glkcDJaTfniOqKOfsvpP3Hw_7tXIvVOVhLlOST8g1za9cEluoYasl6Vcug8e_88FYdRKuS2kuSCR4LdfHXXv1mJfT_sS8DtWISkmXpJLvlKo7eI9gNhYabfn-A5bk3gkHPqV34HlN2OerJMoACs6rH4AtTC98b02kRhHGOFoCUX20FsTZfkT6feh4Avkwll8fBEvJmKfwzxF0M93YfKSJAntqWddjf3q0rlfOJkeSOwAbJQMyW_jl0ycIDUlCN7lbdmNkB0ikPXKtb0d4cF8V83W_RoK-Nbh2YiI7aSnq4yfgZNxYVm2a-iaEyQWQKD1NK4-3Nv_-picYl0308kVKzJ8C-p31oEkbBwA7YQ50Hezuu09ReKfDBrZvE9sSIn1GTZpHsjYL6dPOExsTz9z6x7J3MmAiAQaForHNaYAR2s05FZbpR3dQ19xFhubcJpP5Z8i7mnjIO52tUxJeg3rpbO6-h1LxmJTD-MCJpY37xoI6vuSk6rlvw-FPi22vDjD6SwewGwYhejmT2GXtGevzFOsUK5lovvx35vRzS0wCdGvA0MxDP5VRdcyn_GG-wQeExWKoj8N8be8bGG4G_eA8eRDs1qkjVizYwDj3rbuvY25okXEl4wVpMz1Cw-9Y1btLxITkgBeeCOY3tLy1CHOohR6HqRHUoV3TbQ9zTYy-2Xvf=w877-h427-no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DCGAN is a GAN with a generator designed to do for generate larger RGB images using convolutional layers.\n",
    "\n",
    "Here is the DCGAN architecture:\n",
    "\n",
    "<img src=\"img/dcgan2.png\" title=\"DCGAN\" style=\"width: 640px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some additional required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 6969\n",
    "# seed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define some important variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"data\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 0\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 100 # Original is 5 on a dataset of 1 million\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight initialization\n",
    "\n",
    "Here is a weight initialization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "You will need to follow these conceptual instructions.\n",
    "\n",
    "1. Create noise\n",
    "2. Input noise to generator network to get fake images\n",
    "3. Input fake images to discriminator and detect it that true or false. Calculate $loss_{fake}$ with **True** probability\n",
    "4. Input real images to discriminator and detect it that true or false. Calculate $loss_{real}$ with **True** probability\n",
    "5. $loss_{d} = (loss_{fake} + loss_{real})$\n",
    "6. back propagation discriminator network.\n",
    "7. Input fake images to discriminator and detect it that true or false. Calculate $loss_{gan}$ with **Fake** probability\n",
    "8. back propagation generator network.\n",
    "9. loop it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3949ab53412affcb5d03b522f19a82b",
     "grade": true,
     "grade_id": "cell-9e3ace3b24d17aa1",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "737822d76891d682150ce3d56f1c0a46",
     "grade": false,
     "grade_id": "cell-efa5c29c355cca4e",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### Take-home exercise (50 points)\n",
    "\n",
    "Find another interesting image generation application of the DCGAN and implement it. Demonstate your results in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
